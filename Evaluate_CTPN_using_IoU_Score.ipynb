{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e42qed_6Mmq7",
        "outputId": "4fd4b3a6-4792-4ab4-ef49-3ca429081e77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPYEIAL0Bxhs",
        "outputId": "4b3192fd-bd36-4cec-dcfb-23b7a9966750"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1QugxYUpNnNSxf-TEL_ZaWp6mW79dKh92/ctpn\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/ctpn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCeuflVWjLQD",
        "outputId": "794b26b2-052e-4984-f5b1-906adc017867"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==1.13.2\n",
            "  Downloading tensorflow-1.13.2-cp37-cp37m-manylinux1_x86_64.whl (92.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 92.7 MB 34 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.2) (1.19.5)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.2) (0.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.2) (1.1.0)\n",
            "Collecting keras-applications>=1.0.6\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 9.3 MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n",
            "  Downloading tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367 kB)\n",
            "\u001b[K     |████████████████████████████████| 367 kB 75.3 MB/s \n",
            "\u001b[?25hCollecting tensorboard<1.14.0,>=1.13.0\n",
            "  Downloading tensorboard-1.13.1-py3-none-any.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 62.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.2) (1.0.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.2) (1.43.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.2) (3.17.3)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.2) (0.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.2) (0.37.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.2) (1.1.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.2) (1.15.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.13.2) (3.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.2) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.2) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.2) (4.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.2) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.2) (3.10.0.2)\n",
            "Collecting mock>=2.0.0\n",
            "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==1.13.2) (1.5.2)\n",
            "Installing collected packages: mock, tensorflow-estimator, tensorboard, keras-applications, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.7.0\n",
            "    Uninstalling tensorflow-estimator-2.7.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.7.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.7.0\n",
            "    Uninstalling tensorboard-2.7.0:\n",
            "      Successfully uninstalled tensorboard-2.7.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.7.0\n",
            "    Uninstalling tensorflow-2.7.0:\n",
            "      Successfully uninstalled tensorflow-2.7.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.13.2 which is incompatible.\u001b[0m\n",
            "Successfully installed keras-applications-1.0.8 mock-4.0.3 tensorboard-1.13.1 tensorflow-1.13.2 tensorflow-estimator-1.13.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==1.13.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dK-i8TAFypsX"
      },
      "outputs": [],
      "source": [
        "import os, sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import time\n",
        "import math\n",
        "from imutils.object_detection import non_max_suppression\n",
        "from google.colab.patches import cv2_imshow\n",
        "from operator import itemgetter\n",
        "from ast import literal_eval\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ad71YX-7bUF",
        "outputId": "61d75c53-9ed5-4356-8c40-db4aa9a63d28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ]
        }
      ],
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import glob\n",
        "import os\n",
        "import shutil\n",
        "import sys\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.platform import gfile\n",
        "import time\n",
        "\n",
        "sys.path.append(os.getcwd())\n",
        "from lib.fast_rcnn.config import cfg, cfg_from_file\n",
        "from lib.fast_rcnn.test import _get_blobs\n",
        "from lib.text_connector.detectors import TextDetector\n",
        "from lib.text_connector.text_connect_cfg import Config as TextLineCfg\n",
        "from lib.rpn_msr.proposal_layer_tf import proposal_layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxJY-mM4ndC4"
      },
      "source": [
        "# Truth Values CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "px0eLorSBWv0"
      },
      "outputs": [],
      "source": [
        "def initializeDF():\n",
        "  # Load the truth values CSV for test set\n",
        "  test_values = \"/content/drive/MyDrive/Datasets/RoadTextVideos/Truthvalues.csv\"\n",
        "  df = pd.read_csv(test_values)\n",
        "  df[\"pred_Bbox\"] = None\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZfJc8DXoeXfg"
      },
      "outputs": [],
      "source": [
        "df = initializeDF()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o2xLWqU7mmf"
      },
      "source": [
        "# CTPN IMPLEMENTATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "omacjv507l9D"
      },
      "outputs": [],
      "source": [
        "def resize_im(im, scale, max_scale=None):\n",
        "    f = float(scale) / min(im.shape[0], im.shape[1])\n",
        "    if max_scale != None and f * max(im.shape[0], im.shape[1]) > max_scale:\n",
        "        f = float(max_scale) / max(im.shape[0], im.shape[1])\n",
        "    return cv2.resize(im, None, None, fx=f, fy=f, interpolation=cv2.INTER_LINEAR), f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0XqNrYX0ERM"
      },
      "outputs": [],
      "source": [
        "def draw_boxes(img, image_name, boxes, scale, video):\n",
        "    base_name = image_name.split('/')[-1]\n",
        "    p_bboxes = []\n",
        "    filename = OUTPUT_DIR + video + '/' + '{}_{}.txt'.format(video,base_name.split('.')[0])\n",
        "    #print(filename)\n",
        "    with open(filename, 'w') as f:\n",
        "        for box in boxes:\n",
        "            if np.linalg.norm(box[0] - box[1]) < 5 or np.linalg.norm(box[3] - box[0]) < 5:\n",
        "                continue\n",
        "            if box[8] >= 0.9:\n",
        "                color = (0, 255, 0)\n",
        "            elif box[8] >= 0.8:\n",
        "                color = (255, 0, 0)\n",
        "            cv2.line(img, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), color, 2)\n",
        "            cv2.line(img, (int(box[0]), int(box[1])), (int(box[4]), int(box[5])), color, 2)\n",
        "            cv2.line(img, (int(box[6]), int(box[7])), (int(box[2]), int(box[3])), color, 2)\n",
        "            cv2.line(img, (int(box[4]), int(box[5])), (int(box[6]), int(box[7])), color, 2)\n",
        "\n",
        "            min_x = min(int(box[0] / scale), int(box[2] / scale), int(box[4] / scale), int(box[6] / scale))\n",
        "            min_y = min(int(box[1] / scale), int(box[3] / scale), int(box[5] / scale), int(box[7] / scale))\n",
        "            max_x = max(int(box[0] / scale), int(box[2] / scale), int(box[4] / scale), int(box[6] / scale))\n",
        "            max_y = max(int(box[1] / scale), int(box[3] / scale), int(box[5] / scale), int(box[7] / scale))\n",
        "\n",
        "            line = ','.join([str(min_x), str(min_y), str(max_x), str(max_y)]) + '\\r\\n'\n",
        "            f.write(line)\n",
        "            p_bboxes.append({'x1':min_x,'x2':max_x,'y1':min_y,'y2':max_y})\n",
        "\n",
        "    img = cv2.resize(img, None, None, fx=1.0 / scale, fy=1.0 / scale, interpolation=cv2.INTER_LINEAR)\n",
        "    cv2.imwrite(os.path.join(OUTPUT_DIR,video,base_name), img)\n",
        "    return p_bboxes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDs0JCgy-BEk",
        "outputId": "2ff00fd2-3c8d-4e5f-8fd0-57794124193a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From <ipython-input-10-32508dafc3a5>:7: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.gfile.GFile.\n"
          ]
        }
      ],
      "source": [
        "#Initialize once\n",
        "\n",
        "cfg_from_file('ctpn/text.yml')\n",
        "# init session\n",
        "config = tf.ConfigProto(allow_soft_placement=True)\n",
        "sess = tf.Session(config=config)\n",
        "with gfile.FastGFile('data/ctpn.pb', 'rb') as f:\n",
        "    graph_def = tf.GraphDef()\n",
        "    graph_def.ParseFromString(f.read())\n",
        "    sess.graph.as_default()\n",
        "    tf.import_graph_def(graph_def, name='')\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "input_img = sess.graph.get_tensor_by_name('Placeholder:0')\n",
        "output_cls_prob = sess.graph.get_tensor_by_name('Reshape_2:0')\n",
        "output_box_pred = sess.graph.get_tensor_by_name('rpn_bbox_pred/Reshape_1:0')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CsX2SZv8kzs"
      },
      "outputs": [],
      "source": [
        "def detectCTPN(video):\n",
        "  # Make output folder for video\n",
        "  if (os.path.exists(OUTPUT_DIR + video + \"/\")==False):\n",
        "    os.makedirs(OUTPUT_DIR + video + \"/\")\n",
        "\n",
        "  im_names = glob.glob(os.path.join(cfg.DATA_DIR, video, '*.jpg'))\n",
        "\n",
        "  for im_name in im_names:\n",
        "    # Skip if file already exists in output dir\n",
        "    im_output_path = OUTPUT_DIR + video + \"/\" + im_name.split('/')[-1]\n",
        "    if (os.path.exists(im_output_path)):\n",
        "      #print(\"skipping \" + im_name)\n",
        "      continue\n",
        "    #print(('Demo for {:s}'.format(im_name)))\n",
        "    start = time.time()\n",
        "    img = cv2.imread(im_name)\n",
        "    img, scale = resize_im(img, scale=TextLineCfg.SCALE, max_scale=TextLineCfg.MAX_SCALE)\n",
        "    blobs, im_scales = _get_blobs(img, None)\n",
        "    if cfg.TEST.HAS_RPN:\n",
        "      im_blob = blobs['data']\n",
        "      blobs['im_info'] = np.array([[im_blob.shape[1], im_blob.shape[2], im_scales[0]]],dtype=np.float32)\n",
        "      cls_prob, box_pred = sess.run([output_cls_prob, output_box_pred], feed_dict={input_img: blobs['data']})\n",
        "      rois, _ = proposal_layer(cls_prob, box_pred, blobs['im_info'], 'TEST', anchor_scales=cfg.ANCHOR_SCALES)\n",
        "\n",
        "      scores = rois[:, 0]\n",
        "      boxes = rois[:, 1:5] / im_scales[0]\n",
        "      textdetector = TextDetector()\n",
        "      boxes = textdetector.detect(boxes, scores[:, np.newaxis], img.shape[:2])\n",
        "      costTime = (time.time()-start)\n",
        "      #print(\"cost time: {:.2f}s\".format(costTime))\n",
        "\n",
        "      p_bboxes = draw_boxes(img, im_name, boxes, scale, video)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVJhbnhykrvR"
      },
      "source": [
        "# RUN CTPN HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDKMf-6W8s0O"
      },
      "outputs": [],
      "source": [
        "OUTPUT_DIR = \"/content/drive/MyDrive/Datasets/RoadTextVideos/testOutputCTPN/\"\n",
        "INPUT_DIR = \"/content/drive/MyDrive/Datasets/RoadTextVideos/test/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fi1FOkQrA8hJ"
      },
      "outputs": [],
      "source": [
        "# Change this for 700,800 and 900 folder\n",
        "cfg.DATA_DIR = '/content/drive/MyDrive/Datasets/RoadTextVideos/test/900'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xh7Yb60dhVo-",
        "outputId": "5b783687-8fe8-434a-f0b4-4fa93a8f0e5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [1:31:55<00:00, 2757.59s/it]\n"
          ]
        }
      ],
      "source": [
        "# Run for videos\n",
        "for video in tqdm(range(951,953)):\n",
        "  detectCTPN(str(video))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iy00wgfll13J"
      },
      "source": [
        "# EVALUATION IMPLEMENTATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2U3NVrLg8RiN"
      },
      "outputs": [],
      "source": [
        "def IOUScore(boxA,boxB):\n",
        "    x1,x2,y1,y2 = boxA['x1'], boxA['x2'], boxA['y1'], boxA['y2']\n",
        "    x3,x4,y3,y4 = boxB['x1'], boxB['x2'], boxB['y1'], boxB['y2']\n",
        "\n",
        "    dx = min(x2, x4) - max(x1, x3)\n",
        "    dy = min(y2, y4) - max(y1,y3)\n",
        "    if (dx>=0) and (dy>=0):\n",
        "        area_inter = dx*dy\n",
        "\n",
        "    else:\n",
        "        area_inter = 0\n",
        "    # print(area_inter)\n",
        "\n",
        "    width_box1 = abs(x2-x1)\n",
        "    height_box1 = abs(y2-y1)\n",
        "    width_box2 = abs(x4-x3)\n",
        "    height_box2 = abs(y4-y3)\n",
        "\n",
        "    area_box1 = width_box1*height_box1\n",
        "    area_box2 = width_box2*height_box2\n",
        "\n",
        "    # print(area_box1)\n",
        "    # print(area_box2)\n",
        "    area_union = area_box1 + area_box2 - area_inter\n",
        "\n",
        "    iou = area_inter/area_union\n",
        "    return iou"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggaDK3-WY8BI"
      },
      "outputs": [],
      "source": [
        "def getBboxVal(vid,frame):\n",
        "\n",
        "  truthValue = df.loc[(df['videoName'] == int(vid)) & (df['index'] == int(frame)),\"values\"].values[0]\n",
        "  if(isinstance(truthValue,str) is False):\n",
        "    if(math.isnan(truthValue)):\n",
        "      truthListSorted=[]\n",
        "  else:\n",
        "    truthListUnsorted = literal_eval(truthValue)\n",
        "    # Sort List w.r.t x1\n",
        "    truthListSorted = sorted(truthListUnsorted, key = itemgetter('x1'))\n",
        "\n",
        "  return truthListSorted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TEPqGGGeyeQ"
      },
      "outputs": [],
      "source": [
        "def getIOUScoreFromBbox(p_bboxes,gt_bboxes,threshold):\n",
        "  # Search for match between Ground Truth and predicted bbox\n",
        "  tp=0\n",
        "  fp=0\n",
        "  tn=0\n",
        "  for p_box in p_bboxes:\n",
        "    for gt_box in gt_bboxes:\n",
        "      iou = IOUScore(p_box,gt_box)\n",
        "      if (iou>=threshold):\n",
        "        #True Positive\n",
        "        # print(\"true positive \" + str(iou))\n",
        "        tp+=1\n",
        "        break\n",
        "  fp = len(p_bboxes) - tp\n",
        "  fn = len(gt_bboxes) - tp\n",
        "\n",
        "  return tp,fp,fn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5NNM7upuR5Nf"
      },
      "outputs": [],
      "source": [
        "def evaluateCTPN(threshold):\n",
        "  #Evaluating CTPN Model for the test set\n",
        "  TP=0\n",
        "  FP=0\n",
        "  FN=0\n",
        "\n",
        "  # Find all txt files under the output directory (including subdirectories)\n",
        "  file_names = glob.glob(OUTPUT_DIR + '*/*.txt')\n",
        "\n",
        "  for file in file_names:\n",
        "    # print(\"FILENAME \"+ file)\n",
        "    base_name = file.split('/')[-1]\n",
        "\n",
        "    # Get video and frame number for ground truth comparison\n",
        "    vid = base_name.split('_')[0]\n",
        "    frame = base_name.split('_')[1].split('.')[0]\n",
        "    # print(\"vid \" + vid)\n",
        "    # print(\"frame \" + frame)\n",
        "\n",
        "    # Read the file and get the predicted bbox values\n",
        "    p_bboxes = []\n",
        "    Lines = open(file, 'r').readlines() # Multiple bounding boxes in one img\n",
        "    for line in Lines:\n",
        "      x1,y1,x2,y2 = line.split(',')\n",
        "      p_bboxes.append({'x1':int(x1),'x2':int(x2),'y1':int(y1),'y2':int(y2)})\n",
        "    # print(p_bboxes)\n",
        "\n",
        "    #Get ground truth bbox values\n",
        "    gt_bboxes = getBboxVal(vid,frame)\n",
        "    # print(gt_bboxes)\n",
        "\n",
        "    # Compare predicted bbox values to ground truth values\n",
        "    tp,fp,fn = getIOUScoreFromBbox(p_bboxes,gt_bboxes,threshold)\n",
        "\n",
        "    TP+=tp\n",
        "    FP+=fp\n",
        "    FN+=fn\n",
        "\n",
        "  return TP,FP,FN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wb7teGNHl7pD"
      },
      "source": [
        "# RUN EVALUATION HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLwVh9jogv10"
      },
      "outputs": [],
      "source": [
        "TP,FP,FN = evaluateCTPN(0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWCDh5hAgpnr",
        "outputId": "ec5b5d3e-897c-4be7-db95-4c1432ad9aad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision  0.10909090909090909 \n",
            "Recall  0.1323529411764706\n"
          ]
        }
      ],
      "source": [
        "Precision = TP/(TP+FP)\n",
        "Recall = TP/(TP+FN)\n",
        "print(\"Precision \",Precision,\"\\nRecall \",Recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WrzAlJF2mcJ6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}